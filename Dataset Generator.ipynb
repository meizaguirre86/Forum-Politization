{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import urlopen, Request\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "import time\n",
    "import io\n",
    "import hashlib\n",
    "import requests\n",
    "\n",
    "stopwords = set(stopwords.words('spanish'))\n",
    "political_keys = r\"C:\\Users\\meiza\\Documents\\GitHub\\Forum-Politization\\Dataset\\political_keys.csv\"\n",
    "dataset = r\"C:\\Users\\meiza\\Documents\\GitHub\\Forum-Politization\\Dataset\\dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A PARTIR DE UN HILO DEVOLVEMOS TÍTULO Y MENSAJES\n",
    "\n",
    "def Webscrap(hilo):\n",
    "    #time.sleep(1)\n",
    "  \n",
    "    #REALIZAMOS LA LLAMADA\n",
    "    root_url = \"https://www.forocoches.com/foro/showthread.php?t=\"\n",
    "        \n",
    "    page_html = s.get(root_url+hilo)\n",
    "    page_soup = soup(page_html.content, 'html5lib')\n",
    "\n",
    "\n",
    "        \n",
    "    #COGEMOS LOS MENSAJES Y TITULO\n",
    "    #page_soup = soup(page_html, \"html5lib\")\n",
    "    titulo = page_soup.findAll(\"span\", {\"class\": \"cmega\"})\n",
    "\n",
    "    if not(titulo == []):\n",
    "        titulo = titulo[0].text\n",
    "\n",
    "\n",
    "        mensajes = page_soup.findAll(\"div\", {\"id\": lambda x: x and x.startswith('post_message')})\n",
    "\n",
    "    \n",
    "        #QUITAMOS QUOTES\n",
    "        i = 0\n",
    "        for mensaje in mensajes:\n",
    "            if (mensaje.div != None):\n",
    "                mensaje.div.extract()\n",
    "            #SÓLO EL TEXTO\n",
    "            mensajes[i] = mensaje.text\n",
    "        \n",
    "            #QUITAMOS LOS PARRAFOS Y DOBLES ESPACIOS\n",
    "            mensajes[i] = mensajes[i].replace('\\n', ' ').replace('\\r', '').lower()\n",
    "            mensajes[i] = ' '.join(mensajes[i].split())\n",
    "            i += 1\n",
    "\n",
    "\n",
    "        return titulo,mensajes\n",
    "    else:\n",
    "        return None,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NORMALIZAMOS EL TEXTO\n",
    "def Normalize(text):\n",
    "    #QUITAMOS ACENTOS\n",
    "        \n",
    "    \n",
    "    #QUITAMOS \\n y \\r. TEXTO EN MINÚSCULA\n",
    "    text = text.replace('\\n', ' ').replace('\\r', '').lower()\n",
    "    \n",
    "    #QUITAMOS NÚMEROS\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    \n",
    "    #QUITAMOS PUNTUACIÓN\n",
    "    text = \"\".join(l for l in text if l not in (string.punctuation,'?','¿',',','.'))\n",
    "    \n",
    "    #QUITAMOS DOBLES ESPACIOS\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    #STEMMING Y QUITAMOS STOPWORDS\n",
    "    stemmer = SnowballStemmer(\"spanish\")\n",
    "    words = text.split()\n",
    "    text = ''\n",
    "    for word in words:\n",
    "        if not word in stopwords:\n",
    "            stemmed_word = stemmer.stem(word)\n",
    "            text = text + \" \" + stemmed_word\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCIÓN PARA VER SI EL TÍTULO INDICA QUE ES UN HILO POLÍTICO\n",
    "\n",
    "def Ispolitical(titulo):\n",
    "    political = False\n",
    "    \n",
    "    #Normalizamos titulo\n",
    "    titulo = Normalize(titulo)\n",
    "    titulo = titulo.split()\n",
    "\n",
    "    #Cruzamos nuestro título con nuestras palabras clave para saber si es título político\n",
    "    with open(political_keys, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in reader:\n",
    "            key = Normalize(row[0]).strip()\n",
    "            for palabra in titulo:\n",
    "                if (key == palabra):\n",
    "                    political = True\n",
    "    return political    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCIÓN PARA ECSRIBIR EN EL DATASET\n",
    "\n",
    "def Writedatasetpolitico(mensajes):\n",
    "    with io.open(dataset, 'a', newline='',encoding=\"utf-8\") as ds:\n",
    "        dataset_writer = csv.writer(ds, delimiter=',', quotechar=\"'\", quoting=csv.QUOTE_NONNUMERIC)\n",
    "        for mensaje in mensajes:\n",
    "            dataset_writer.writerow([1, mensaje])\n",
    "\n",
    "def Writedatasetnopolitico(mensajes):\n",
    "    with io.open(dataset, 'a', newline='',encoding=\"utf-8\") as ds:\n",
    "        dataset_writer = csv.writer(ds, delimiter=',', quotechar=\"'\", quoting=csv.QUOTE_NONNUMERIC)\n",
    "        for mensaje in mensajes:\n",
    "            dataset_writer.writerow([0, mensaje])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INICIAMOS SESIÓN\n",
    "s = requests.Session()\n",
    "username = '<USERNAME>'\n",
    "password = '<PASSWORD>'\n",
    "BASE_URL = 'https://www.forocoches.com/foro'\n",
    "    \n",
    "r = s.post(BASE_URL + '/login.php?do=login', {\n",
    "'vb_login_username':        username,\n",
    "'vb_login_password':        password,\n",
    "'vb_login_md5password':     hashlib.md5(password.encode()).hexdigest(),\n",
    "'vb_login_md5password_utf': hashlib.md5(password.encode(\"utf-8\")).hexdigest(),\n",
    "\n",
    "'cookieuser': 1,\n",
    "'do': 'login',\n",
    "'s': '',\n",
    "'securitytoken': 'guest'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A ver si os enteráis que no vais a coger la paguita tan fácil palurdos\n",
      "Risas manifa negros Madrid\n",
      "Alguna vez te han comido el anillo negro?\n"
     ]
    }
   ],
   "source": [
    "#BUSCADOR DE HILOS POLITIZADOS PARA AÑADIRLOS AL DATASET\n",
    "\n",
    "hilo_inicio=7996396\n",
    "hilo_final=7996500\n",
    "\n",
    "for i in range(hilo_inicio, hilo_final+1):\n",
    "    titulo, mensajes = Webscrap(str(i))\n",
    "    if titulo != None:\n",
    "        politico = Ispolitical(titulo)\n",
    "        if politico:\n",
    "            print(titulo)\n",
    "            Writedatasetpolitico(mensajes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clara Ponsati y Puigdemont en Twitter + nazis\n"
     ]
    }
   ],
   "source": [
    "#AÑADIR HILOS AL DATASET MANUALMENTE\n",
    "hilo='7781086&page=11'\n",
    "titulo, mensajes = Webscrap(hilo)\n",
    "Writedatasetpolitico(mensajes)\n",
    "print(titulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
